{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\andre\\AppData\\Local\\Temp\\ipykernel_19388\\2723146465.py:17: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-whitegrid')\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from paths import *\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from src.SERS_dataset import IterDataset\n",
    "from src.generate_data2 import pseudoVoigtSimulatorTorch\n",
    "from src.plotting.save_plot import save_plot\n",
    "from src.plotting.VAE_plotting import plot_loss, plt_latent_space_ellipses, plt_reconstructions, plot_losses\n",
    "# import make_axes_locatable\n",
    "import numpy as np\n",
    "import dill\n",
    "import io\n",
    "\n",
    "# matplotlib style seaborn-whitegrid\n",
    "plt.style.use('seaborn-whitegrid')\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that has been trained on GPU on CPU. Source https://github.com/pytorch/pytorch/issues/16797\n",
    "class CPU_Unpickler(dill.Unpickler):\n",
    "    def find_class(self, module, name):\n",
    "        if module == 'torch.storage' and name == '_load_from_bytes':\n",
    "            return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
    "        else: return super().find_class(module, name)\n",
    "\n",
    "def load_dill(file_name, experiment):\n",
    "    file_name = os.path.join(results_dir, experiment, file_name)\n",
    "    with open(file_name, 'rb') as f:\n",
    "        contents = CPU_Unpickler(f).load()\n",
    "    autoencoder = contents[\"model\"]\n",
    "    train_loss = contents[\"train_loss\"]\n",
    "    generator_num = contents[\"generator\"]\n",
    "\n",
    "    return autoencoder, train_loss, generator_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_names = {\"holographic-trooper-340\": 3, \"star-speeder-330\": 2, \"scruffy-looking-ewok-309\": 1}\n",
    "labels_dict = {1: \"alpha\", 2: \"c\", 3: [\"c\", \"alpha\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = pseudoVoigtSimulatorTorch(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator 3\n",
      "   loss 401.0875133167614\n",
      "   kl 16.68412277915261\n",
      "   elbo -401.0875133167614\n",
      "   logpx -384.40340909090907\n",
      "   MSE 0.2715077373114499\n",
      "\n",
      "\n",
      "Generator 2\n",
      "   loss 382.7434248490767\n",
      "   kl 10.656651323491877\n",
      "   elbo -382.7434248490767\n",
      "   logpx -372.0867808948864\n",
      "   MSE 0.2591911093755202\n",
      "\n",
      "\n",
      "Generator 1\n",
      "   loss 367.4722373268821\n",
      "   kl 3.926317236640237\n",
      "   elbo -367.4722373268821\n",
      "   logpx -363.54593172940343\n",
      "   MSE 0.2506502744826404\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# don't show plots in notebook\n",
    "# plt.ioff()\n",
    "\n",
    "\n",
    "for model_name, generator_num in model_names.items():\n",
    "\n",
    "    autoencoder, train_loss, generator_num = load_dill(f\"{model_name}.dill\", \"2_VAE\")\n",
    "\n",
    "    print(\"Generator\", generator_num)\n",
    "    for key, value in train_loss.items():\n",
    "        print(\"  \", key, value[-1])\n",
    "    print()\n",
    "\n",
    "    # print(\"Generator\", generator_num, \", Loss: \", train_loss[-1])\n",
    "\n",
    "    generator = ps.predefined_generator(generator_num)\n",
    "    dset_train = IterDataset(generator)\n",
    "    train_loader = torch.utils.data.DataLoader(dset_train, batch_size=100, pin_memory=cuda)\n",
    "\n",
    "    x, y = next(iter(train_loader))\n",
    "    x = x.to(device)\n",
    "    y = y.to(device)\n",
    "    z, mu, logvar = autoencoder.encode(x)\n",
    "    sigma = torch.exp(0.5 * logvar)\n",
    "    x_hat = autoencoder.decode(z)\n",
    "    x_hat_mu = autoencoder.decode(mu)\n",
    "\n",
    "    x = x.cpu().detach().numpy()\n",
    "    x_hat = x_hat.cpu().detach().numpy()\n",
    "    x_hat_mu = x_hat_mu.cpu().detach().numpy()\n",
    "    sigma = sigma.cpu().detach().numpy()\n",
    "    mu = mu.cpu().detach().numpy()\n",
    "    z = z.cpu().detach().numpy()\n",
    "\n",
    "    # recons = autoencoder.decode(z)\n",
    "    label = labels_dict[generator_num]\n",
    "\n",
    "    ll = {\"c\": 0, \"gamma\": 1, \"eta\": 2, \"alpha\": 3}\n",
    "    labels = []\n",
    "    if isinstance(label, list):\n",
    "        for l in label:\n",
    "            labels.append(y[:,ll[l]])\n",
    "    else:\n",
    "        labels.append(y[:,ll[label]])\n",
    "        label = [label]\n",
    "\n",
    "    # save plots \n",
    "    plot = plt_latent_space_ellipses(z, mu, sigma, labels, label, 2)\n",
    "    save_plot(plot, os.path.join(report_dir, \"figures\", \"results\", \"2_VAE\", \"vae_latent_space_\" + \"_\".join(label)), [\"pdf\", \"png\"])\n",
    "    plot =  plot_losses(train_loss, generator_num)\n",
    "    save_plot(plot, os.path.join(report_dir, \"figures\", \"results\", \"2_VAE\", \"vae_losses_\" + \"_\".join(label)), [\"pdf\", \"png\"])\n",
    "    plot = plt_reconstructions(x, x_hat, x_hat_mu, y, n=3)\n",
    "    save_plot(plot, os.path.join(report_dir, \"figures\", \"results\", \"2_VAE\", \"vae_reconstructions_\" + \"_\".join(label)), [\"pdf\", \"png\"])\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bachelor-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
